# OpenstackGPUService

## Overview

This service provides a REST-API to retrieve OpenStack Flavor GPU Info.



This server was generated by the [OpenAPI Generator](https://openapi-generator.tech) project. By using the
[OpenAPI-Spec](https://openapis.org) from a remote server, you can easily generate a server stub.  This
is an example of building a OpenAPI-enabled Flask server.

This example uses the [Connexion](https://github.com/zalando/connexion) library on top of Flask.

## Requirements
Python 3.5.2+

## Usage
To run the server, please execute the following from the root directory:

```
pip3 install -r requirements.txt
python3 -m openapi_server
```

and open your browser to here:

```
http://localhost:8080/ui/
```

Your OpenAPI definition lives here:

```
http://localhost:8080/openapi.json
```

##  (Units-)Test

OpenstackGPUservice comes with a full set of units test. All  call towarding the Openstack API
are mocked using unittest.mock functionality.

###  Mock Test Setup
The Mock test setup "simulates"  the following setup.
- two aggregates (for GPU and non GPU based hypervisors)
- three hypervisor available (28 cores, 384 cores, 4 TB local disc space), two of them having two GPU on board
- two instances running (de.NBI large, de.NBI GPU V100 medium)


To launch the integration tests, use tox:
```
sudo pip install tox
tox
```



## Running with Docker

To run the server on a Docker container, please execute the following from the root directory:

```bash
# building the image
docker build -t openapi_server .

# starting up a container
docker run -p 8080:8080 openapi_server
```

## Running from CLI
The server functionality can also be tested using a simple cmdlineclient.

```
pip3 install -r requirements
PYTHONPATH=. python3 cli --help
```
